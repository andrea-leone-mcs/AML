{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = 'data/dev_data/dev_data/slider/train'\n",
    "TEST_DIR = 'data/dev_data/dev_data/slider/test'\n",
    "SAMPLE_RATE = 16000\n",
    "DOWNSAMPLE_FACTOR = 10\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from scipy.io import wavfile\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.spatial.distance import cosine, euclidean\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTRdic = dict()\n",
    "for file_name in os.listdir(TRAIN_DIR):\n",
    "    file_path = os.path.join(TRAIN_DIR, file_name)\n",
    "    _, audio_data = wavfile.read(file_path)\n",
    "    id = file_name.split('_')[2]\n",
    "    if id in XTRdic:\n",
    "        XTRdic[id].append(np.array(audio_data[::DOWNSAMPLE_FACTOR]))\n",
    "    else:\n",
    "        XTRdic[id] = [audio_data[::DOWNSAMPLE_FACTOR]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTEdic = dict()\n",
    "yTEdic = dict()\n",
    "for file_name in os.listdir(TEST_DIR):\n",
    "    file_path = os.path.join(TEST_DIR, file_name)\n",
    "    _, audio_data = wavfile.read(file_path)\n",
    "    parts = file_name.split('_')\n",
    "    id = parts[2]\n",
    "    label = 1 if parts[0] == 'normal' else 0\n",
    "    if id in XTEdic:\n",
    "        XTEdic[id].append(np.array(audio_data[::DOWNSAMPLE_FACTOR]))\n",
    "        yTEdic[id].append(label)\n",
    "    else:\n",
    "        XTEdic[id] = [audio_data[::DOWNSAMPLE_FACTOR]]\n",
    "        yTEdic[id] = [label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = sorted(XTRdic.keys())\n",
    "for id in ids:\n",
    "    XTRdic[id] = np.vstack(XTRdic[id])\n",
    "    XTEdic[id] = np.vstack(XTEdic[id])\n",
    "    yTEdic[id] = np.array(yTEdic[id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "\n",
    "def estimate_pitch(audio_data):\n",
    "    \"\"\"\n",
    "    Estimate pitch from audio data.\n",
    "\n",
    "    Parameters:\n",
    "    - audio_data: numpy array containing audio samples.\n",
    "\n",
    "    Returns:\n",
    "    - pitches: numpy array containing estimated pitch values.\n",
    "    \"\"\"\n",
    "    # Estimate pitch using librosa\n",
    "    pitches, magnitudes = librosa.piptrack(y=audio_data, sr=SAMPLE_RATE/DOWNSAMPLE_FACTOR)\n",
    "    \n",
    "    return pitches\n",
    "\n",
    "def pitch_similarity(pitches1, pitches2):\n",
    "    \"\"\"\n",
    "    Compute similarity based on pitch values using Euclidean distance.\n",
    "\n",
    "    Parameters:\n",
    "    - pitches1: numpy array containing pitch values of the first audio signal.\n",
    "    - pitches2: numpy array containing pitch values of the second audio signal.\n",
    "\n",
    "    Returns:\n",
    "    - similarity: similarity score based on pitch values.\n",
    "    \"\"\"\n",
    "    # Compute Euclidean distance between pitch values\n",
    "    distance = np.linalg.norm(pitches1 - pitches2)\n",
    "    \n",
    "    # Convert distance to similarity score (e.g., inverse)\n",
    "    similarity = 1 / (1 + distance)\n",
    "    \n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phase_correlation(signal1, signal2):\n",
    "    # Compute the complex conjugate of signal1\n",
    "    conj_signal1 = np.conj(signal1)\n",
    "    \n",
    "    # Compute the cross-power spectrum\n",
    "    cross_power_spectrum = signal2 * conj_signal1\n",
    "    \n",
    "    # Compute the phase correlation\n",
    "    phase_corr = np.abs(np.fft.ifft(cross_power_spectrum))\n",
    "    \n",
    "    # Compute the mean or sum of the phase correlation matrix\n",
    "    similarity = np.mean(phase_corr)  # or np.sum(phase_corr)\n",
    "    \n",
    "    return similarity\n",
    "\n",
    "def cross_correlation(signal1, signal2):\n",
    "    # Compute the complex conjugate of signal2\n",
    "    conj_signal2 = np.conj(signal2)\n",
    "    \n",
    "    # Compute the cross-correlation\n",
    "    cross_corr = np.fft.ifft(np.fft.fft(signal1) * conj_signal2)\n",
    "    \n",
    "    return np.mean(cross_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "def compute_mfcc(audio_data, n_mfcc=13):\n",
    "    \"\"\"\n",
    "    Compute Mel-Frequency Cepstral Coefficients (MFCCs) from audio data.\n",
    "\n",
    "    Parameters:\n",
    "    - audio_data: numpy array containing audio samples.\n",
    "    - n_mfcc: number of MFCC coefficients to compute (default: 13).\n",
    "\n",
    "    Returns:\n",
    "    - mfccs: numpy array containing MFCCs.\n",
    "    \"\"\"\n",
    "    # Compute MFCCs\n",
    "    mfccs = librosa.feature.mfcc(y=audio_data.astype(float), sr=SAMPLE_RATE/DOWNSAMPLE_FACTOR, n_mfcc=n_mfcc)\n",
    "    \n",
    "    return mfccs\n",
    "\n",
    "def mfcc_distance(mfcc1, mfcc2):\n",
    "    \"\"\"\n",
    "    Compute the Euclidean distance between two sets of MFCCs.\n",
    "\n",
    "    Parameters:\n",
    "    - mfcc1: numpy array containing MFCCs of the first audio signal.\n",
    "    - mfcc2: numpy array containing MFCCs of the second audio signal.\n",
    "\n",
    "    Returns:\n",
    "    - distance: Euclidean distance between the two sets of MFCCs.\n",
    "    \"\"\"\n",
    "    distance = euclidean(mfcc1.flatten(), mfcc2.flatten())\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fft_distance(signal1, signal2):\n",
    "    \"\"\"\n",
    "    Compute the Euclidean distance between two sets of FFTs.\n",
    "\n",
    "    Parameters:\n",
    "    - signal1: numpy array containing FFT of the first audio signal.\n",
    "    - signal2: numpy array containing FFT of the second audio signal.\n",
    "\n",
    "    Returns:\n",
    "    - distance: Euclidean distance between the two sets of FFTs.\n",
    "    \"\"\"\n",
    "    distance = euclidean(signal1.flatten(), signal2.flatten())\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for id in ids:\n",
    "#     XTR = XTRdic[id]\n",
    "#     XTRmean = np.mean(XTR, axis=0)\n",
    "#     mfcc = compute_mfcc(XTRmean)\n",
    "#     fft = np.fft.fft(XTRmean)\n",
    "#     # avg = fft.mean()\n",
    "\n",
    "#     print(XTRmean.shape)\n",
    "\n",
    "#     scores = []\n",
    "#     for i in range(len(XTR)):\n",
    "#         pc = phase_correlation(XTR[i,:], XTRmean)\n",
    "#         md = mfcc_distance(compute_mfcc(XTR[i,:]), mfcc)\n",
    "#         thisfft = np.fft.fft(XTR[i,:])\n",
    "#         fd = fft_distance(thisfft, fft)\n",
    "#         # fa = avg - thisfft.mean()\n",
    "#         peaks, _ = find_peaks(XTR[i,:])\n",
    "#         scores.append([pc, len(peaks), fd])\n",
    "#     scores = np.array(scores)\n",
    "#     print(scores.shape)\n",
    "    \n",
    "#     # Convert scores to numpy array for easier manipulation\n",
    "#     scores = np.array(scores)\n",
    "\n",
    "#     # Separate the two dimensions\n",
    "#     x = scores[:, 0]\n",
    "#     y = scores[:, 1]\n",
    "#     z = scores[:, 2]\n",
    "    \n",
    "#     # Create a trace\n",
    "#     trace = go.Scatter3d(\n",
    "#         x=x,\n",
    "#         y=y,\n",
    "#         z=z,\n",
    "#         mode='markers',\n",
    "#         marker=dict(\n",
    "#             size=3,\n",
    "#             color=z,                # Color by z value\n",
    "#             colorscale='Viridis',   # Set color scale\n",
    "#             opacity=0.8\n",
    "#         )\n",
    "#     )\n",
    "#     # Create layout\n",
    "#     layout = go.Layout(\n",
    "#     margin=dict(l=0, r=0, b=0, t=0),\n",
    "#     scene=dict(\n",
    "#             xaxis=dict(title='X'),\n",
    "#             yaxis=dict(title='Y'),\n",
    "#             zaxis=dict(title='Z'),\n",
    "#         )\n",
    "#     )\n",
    "#     # Create figure\n",
    "#     fig = go.Figure(data=[trace], layout=layout)\n",
    "\n",
    "#     # Show plot\n",
    "#     fig.show()\n",
    "\n",
    "\n",
    "#     # Create scatter plot\n",
    "#     # plt.scatter(score1, score2, c=colors)\n",
    "#     # plt.xlabel('Score 1')\n",
    "#     # plt.ylabel('Score 2')\n",
    "#     # plt.title('Scatter Plot of Scores')\n",
    "#     # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for id in ids:\n",
    "#     XTR = np.mean(XTRdic[id], axis=0)\n",
    "#     mfcc = compute_mfcc(XTR)\n",
    "#     fft = np.fft.fft(XTR)\n",
    "#     avg = fft.mean()\n",
    "#     XTE = XTEdic[id]\n",
    "#     yTE = yTEdic[id]\n",
    "\n",
    "#     print(XTR.shape)\n",
    "#     print(XTE.shape)\n",
    "\n",
    "#     scores = []\n",
    "#     for i in range(len(XTE)):\n",
    "#         # thisfft = np.fft.fft(XTE[i,:])\n",
    "#         # dist0 = thisfft.T @ thisfft\n",
    "#         # dist0 = dist0*np.conj(dist0)\n",
    "#         # fa = thisfft.mean()\n",
    "#         pc = phase_correlation(XTE[i,:], XTR)\n",
    "#         # md = mfcc_distance(compute_mfcc(XTE[i,:]), mfcc)\n",
    "#         thisfft = np.fft.fft(XTE[i,:])\n",
    "#         fd = fft_distance(thisfft, fft)\n",
    "#         fa = avg - thisfft.mean()\n",
    "        \n",
    "#         peaks, _ = find_peaks(np.abs(np.clip(thisfft-fft, 0, None)), height=40000)\n",
    "#         scores.append([pc, len(peaks), fd])\n",
    "#     scores = np.array(scores)\n",
    "#     print(scores.shape, yTE.shape)\n",
    "    \n",
    "#     # Convert scores to numpy array for easier manipulation\n",
    "#     scores = np.array(scores)\n",
    "\n",
    "#     # Separate the two dimensions\n",
    "#     x = scores[:, 0]\n",
    "#     y = scores[:, 1]\n",
    "#     z = scores[:, 2]\n",
    "    \n",
    "#     # Filter scores based on class\n",
    "#     scores_red = scores[yTE == 0]\n",
    "#     scores_blue = scores[yTE == 1]\n",
    "    \n",
    "#     # Define colors for the classes (assuming yTE is defined)\n",
    "#     colors = np.where(yTE == 0, 'red', 'blue')\n",
    "    \n",
    "#     # Create a trace\n",
    "#     trace = go.Scatter3d(\n",
    "#         x=x,\n",
    "#         y=y,\n",
    "#         z=z,\n",
    "#         mode='markers',\n",
    "#         marker=dict(\n",
    "#             size=3,\n",
    "#             color=colors,                # Color by z value\n",
    "#             colorscale='Viridis',   # Set color scale\n",
    "#             opacity=0.8\n",
    "#         )\n",
    "#     )\n",
    "#     # Create layout\n",
    "#     layout = go.Layout(\n",
    "#     margin=dict(l=0, r=0, b=0, t=0),\n",
    "#     scene=dict(\n",
    "#             xaxis=dict(title='X'),\n",
    "#             yaxis=dict(title='Y'),\n",
    "#             zaxis=dict(title='Z'),\n",
    "#         )\n",
    "#     )\n",
    "#     # Create figure\n",
    "#     fig = go.Figure(data=[trace], layout=layout)\n",
    "\n",
    "#     # Show plot\n",
    "#     fig.show()\n",
    "\n",
    "\n",
    "#     # Create scatter plot\n",
    "#     # plt.scatter(score1, score2, c=colors)\n",
    "#     # plt.xlabel('Score 1')\n",
    "#     # plt.ylabel('Score 2')\n",
    "#     # plt.title('Scatter Plot of Scores')\n",
    "#     # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 00\n",
      "Processing 02\n",
      "Processing 04\n"
     ]
    }
   ],
   "source": [
    "XTRfeatures = dict()\n",
    "XTRmeans = dict()\n",
    "\n",
    "for id in ids:\n",
    "    print(f'Processing {id}')\n",
    "    XTR = XTRdic[id]\n",
    "    XTRmean = np.mean(XTR, axis=0)\n",
    "    mfcc = compute_mfcc(XTRmean)\n",
    "    fft = np.fft.fft(XTRmean)\n",
    "    avg = fft.mean()\n",
    "\n",
    "    features = []\n",
    "    for i in range(len(XTR)):\n",
    "        pc = phase_correlation(XTR[i,:], XTRmean)\n",
    "        md = mfcc_distance(compute_mfcc(XTR[i,:]), mfcc)\n",
    "        thisfft = np.fft.fft(XTR[i,:])\n",
    "        fd = fft_distance(thisfft, fft)\n",
    "        fa = avg - thisfft.mean()\n",
    "        peaks, _ = find_peaks(XTR[i,:])\n",
    "        features.append([pc, md, fd, fa.real, fa.imag, len(peaks)])\n",
    "    \n",
    "    XTRfeatures[id] = np.array(features)\n",
    "    XTRmeans[id] = {\n",
    "        'mean': XTRmean,\n",
    "        'mfcc': mfcc,\n",
    "        'fft': fft,\n",
    "        'avgfft-real': avg.real,\n",
    "        'avgfft-imag': avg.imag\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from scipy.stats import multivariate_normal\n",
    "\n",
    "# scalers = dict()\n",
    "# gaussians = dict()\n",
    "# thresholds = dict()\n",
    "\n",
    "# for id in ids:\n",
    "#     print(f'Processing {id}')\n",
    "#     XTR = XTRfeatures[id]\n",
    "    \n",
    "#     scaler = StandardScaler()\n",
    "#     XTRscaled = scaler.fit_transform(XTR)\n",
    "#     scalers[id] = scaler\n",
    "\n",
    "#     # Estimate mean and covariance matrix from normalized data\n",
    "#     mean = np.mean(XTRscaled, axis=0)\n",
    "#     covariance_matrix = np.cov(XTRscaled, rowvar=False)\n",
    "\n",
    "#     gaussian_distribution = multivariate_normal(mean=mean, cov=covariance_matrix)\n",
    "#     gaussians[id] = gaussian_distribution\n",
    "\n",
    "#     log_likelihoods = gaussian_distribution.logpdf(XTRscaled)\n",
    "#     log_likelihoods.sort()\n",
    "#     threshold = log_likelihoods[int(0.1*len(log_likelihoods))]\n",
    "#     thresholds[id] = threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loglikelihoods = dict()\n",
    "\n",
    "# for id in ids:\n",
    "#     print(f'Processing {id}')\n",
    "#     XTE = XTEdic[id]\n",
    "#     yTE = yTEdic[id]\n",
    "    \n",
    "#     features = []\n",
    "#     for i in range(len(XTE)):\n",
    "#         thisfft = np.fft.fft(XTE[i,:])\n",
    "#         pc = phase_correlation(XTE[i,:], XTRmeans[id]['mean'])\n",
    "#         md = mfcc_distance(compute_mfcc(XTE[i,:]), XTRmeans[id]['mfcc'])\n",
    "#         fd = fft_distance(thisfft, XTRmeans[id]['fft'])\n",
    "#         fa = XTRmeans[id]['avgfft-real'] - thisfft.mean()\n",
    "#         peaks, _ = find_peaks(XTE[i,:])\n",
    "#         features.append([pc, md, fd, fa.real, fa.imag, len(peaks)])\n",
    "    \n",
    "#     XTEfeatures = np.array(features)\n",
    "\n",
    "#     # Normalize test data using the same scaler\n",
    "#     XTEscaled = scalers[id].transform(XTEfeatures)\n",
    "\n",
    "#     # Compute log-likelihood of the test data\n",
    "#     log_likelihood = gaussians[id].logpdf(XTEscaled)\n",
    "#     loglikelihoods[id] = log_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix\n",
    "\n",
    "# for id in ids:\n",
    "#     threshold = thresholds[id]\n",
    "#     yTE = yTEdic[id]\n",
    "#     colors = np.where(yTE == 0, 'red', 'blue')\n",
    "#     print(f'Processing {id}')\n",
    "#     log_likelihood = loglikelihoods[id]\n",
    "#     # Create a scatter plot\n",
    "#     plt.scatter(range(len(log_likelihood)), log_likelihood, c=colors)\n",
    "\n",
    "#     # Add labels and title\n",
    "#     plt.xlabel('Sample')\n",
    "#     plt.ylabel('Log-Likelihood')\n",
    "#     plt.title('Scatter Plot of Log-Likelihoods')\n",
    "\n",
    "#     # Show the plot\n",
    "#     plt.show()\n",
    "\n",
    "#     ypred = np.where(log_likelihood > threshold, 1, 0)\n",
    "#     accuracy = accuracy_score(yTE, ypred)\n",
    "#     auc = roc_auc_score(yTE, ypred)\n",
    "#     conf_mat = confusion_matrix(yTE, ypred)\n",
    "#     # Extract TN, FP, FN, TP from confusion matrix\n",
    "#     TN, FP, FN, TP = conf_mat.ravel()\n",
    "#     # Compute False Positive Rate (FPR)\n",
    "#     fpr = FP / (FP + TN)\n",
    "#     # Compute False Negative Rate (FNR)\n",
    "#     fnr = FN / (FN + TP)\n",
    "\n",
    "#     print(f'AUC: {auc:.2f}')\n",
    "#     print(f'Accuracy: {accuracy:.2f}')\n",
    "#     print(f'FPR: {fpr:.2f}')\n",
    "#     print(f'FNR: {fnr:.2f}')\n",
    "#     print('Confusion Matrix:')\n",
    "#     print(conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 00\n",
      "Components: 1, avg_ll: -7.97, AUC: 0.97, Accuracy: 0.99, FPR: 0.00, FNR: 0.05\n",
      "Components: 2, avg_ll: -7.60, AUC: 0.99, Accuracy: 1.00, FPR: 0.00, FNR: 0.02\n",
      "Components: 4, avg_ll: -7.18, AUC: 0.97, Accuracy: 0.98, FPR: 0.00, FNR: 0.07\n",
      "Components: 8, avg_ll: -6.72, AUC: 0.94, Accuracy: 0.97, FPR: 0.00, FNR: 0.13\n",
      "Processing 02\n",
      "Components: 1, avg_ll: -7.41, AUC: 0.72, Accuracy: 0.63, FPR: 0.48, FNR: 0.08\n",
      "Components: 2, avg_ll: -6.87, AUC: 0.86, Accuracy: 0.84, FPR: 0.18, FNR: 0.10\n",
      "Components: 4, avg_ll: -6.45, AUC: 0.80, Accuracy: 0.77, FPR: 0.28, FNR: 0.11\n",
      "Components: 8, avg_ll: -5.94, AUC: 0.84, Accuracy: 0.82, FPR: 0.20, FNR: 0.12\n",
      "Processing 04\n",
      "Components: 1, avg_ll: -7.96, AUC: 0.77, Accuracy: 0.73, FPR: 0.39, FNR: 0.07\n",
      "Components: 2, avg_ll: -7.39, AUC: 0.77, Accuracy: 0.72, FPR: 0.42, FNR: 0.05\n",
      "Components: 4, avg_ll: -7.13, AUC: 0.76, Accuracy: 0.72, FPR: 0.38, FNR: 0.09\n",
      "Components: 8, avg_ll: -6.83, AUC: 0.75, Accuracy: 0.74, FPR: 0.30, FNR: 0.20\n"
     ]
    }
   ],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix\n",
    "\n",
    "models = dict()\n",
    "\n",
    "for id in ids:\n",
    "    print(f'Processing {id}')\n",
    "    XTR = XTRfeatures[id]\n",
    "    scaler = StandardScaler()\n",
    "    XTRscaled = scaler.fit_transform(XTR)\n",
    "\n",
    "    XTE = XTEdic[id]\n",
    "    yTE = yTEdic[id]\n",
    "    features = []\n",
    "\n",
    "    for i in range(len(XTE)):\n",
    "        thisfft = np.fft.fft(XTE[i,:])\n",
    "        pc = phase_correlation(XTE[i,:], XTRmeans[id]['mean'])\n",
    "        md = mfcc_distance(compute_mfcc(XTE[i,:]), XTRmeans[id]['mfcc'])\n",
    "        fd = fft_distance(thisfft, XTRmeans[id]['fft'])\n",
    "        fa = XTRmeans[id]['avgfft-real'] - thisfft.mean()\n",
    "        peaks, _ = find_peaks(XTE[i,:])\n",
    "        features.append([pc, md, fd, fa.real, fa.imag, len(peaks)])\n",
    "    \n",
    "    XTEfeatures = np.array(features)\n",
    "    # Normalize test data using the same scaler\n",
    "    XTEscaled = scaler.transform(XTEfeatures)\n",
    "    \n",
    "    XTR = XTRscaled\n",
    "    XTE = XTEscaled\n",
    "    \n",
    "    best_model, best_auc, best_threshold = None, None, None\n",
    "\n",
    "    nums_components = [1, 2, 4, 8]\n",
    "    for n_components in nums_components:\n",
    "        gmm = GaussianMixture(n_components=n_components, random_state=RANDOM_STATE)\n",
    "        gmm.fit(XTR)\n",
    "        log_likelihoods = gmm.score_samples(XTR)\n",
    "        log_likelihoods.sort()\n",
    "        threshold = log_likelihoods[int(0.05*len(log_likelihoods))]\n",
    "        avg_ll = log_likelihoods.mean()\n",
    "\n",
    "        test_scores = gmm.score_samples(XTE)\n",
    "        ypred = test_scores > threshold\n",
    "\n",
    "        accuracy = accuracy_score(yTE, ypred)\n",
    "        auc = roc_auc_score(yTE, ypred)\n",
    "        conf_mat = confusion_matrix(yTE, ypred)\n",
    "        TN, FP, FN, TP = conf_mat.ravel()\n",
    "        fpr = FP / (FP + TN)\n",
    "        fnr = FN / (FN + TP)\n",
    "\n",
    "        print(f'Components: {n_components}, avg_ll: {avg_ll:.2f}, AUC: {auc:.2f}, Accuracy: {accuracy:.2f}, FPR: {fpr:.2f}, FNR: {fnr:.2f}')\n",
    "        \n",
    "        if best_auc is None or auc > best_auc:\n",
    "            best_auc = auc\n",
    "            best_model = gmm\n",
    "            threshold = best_threshold"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
