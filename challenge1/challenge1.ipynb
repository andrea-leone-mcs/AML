{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Challenge 1"]},{"cell_type":"code","execution_count":42,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","import os\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","def is_running_on_kaggle():\n","    return \"KAGGLE_KERNEL_RUN_TYPE\" in os.environ and os.environ[\"KAGGLE_KERNEL_RUN_TYPE\"] == \"Interactive\"\n","data_path = '/kaggle/input/' if is_running_on_kaggle() else 'data/'\n","\n","#for dirname, _, filenames in os.walk(data_path):\n","#    for filename in filenames:\n","#        print(os.path.join(dirname, filename))\n","#\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[],"source":["import torch\n","import torchvision\n","from torch.utils.data import Dataset\n","from torchvision.transforms import ToTensor\n","\n","# Imports\n","import warnings\n","import matplotlib.pyplot as plt\n","from torchvision.io import read_image\n","\n","class CactusDataset(Dataset):\n","    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n","        self.img_labels = pd.read_csv(annotations_file)\n","        self.img_dir = img_dir\n","        self.transform = transform\n","        self.target_transform = target_transform\n","\n","    def __len__(self):\n","        return len(self.img_labels)\n","\n","    def __getitem__(self, idx):\n","        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n","        image = read_image(img_path)\n","        label = self.img_labels.iloc[idx, 1]\n","        if self.transform:\n","            image = self.transform(image)\n","        if self.target_transform:\n","            label = self.target_transform(label)\n","        return image, label"]},{"cell_type":"code","execution_count":44,"metadata":{},"outputs":[],"source":["annotations_file = data_path + 'train.csv'\n","img_dir = data_path + 'train/train/'\n","\n","BATCH_SIZE = 32\n","LEARNING_RATE = 1e-3"]},{"cell_type":"code","execution_count":45,"metadata":{},"outputs":[],"source":["# import torch\n","# import torch.nn as nn\n","# import torch.nn.functional as F\n","\n","# class TinyModel(nn.Module):\n","#     def __init__(self):\n","#         super(TinyModel, self).__init__()\n","#         # Define convolutional layers\n","#         self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)\n","#         self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n","#         # Define fully connected layers\n","#         self.fc1 = nn.Linear(32 * 8 * 8, 128)  # 32x32 image downscaled by 2x2 max pooling twice\n","#         self.fc2 = nn.Linear(128, 1)  # Output layer with a single neuron for binary classification\n","\n","#     def forward(self, x):\n","#         # Convolutional layers with ReLU activation and max pooling\n","#         x = F.relu(self.conv1(x))\n","#         x = F.max_pool2d(x, kernel_size=2, stride=2)\n","#         x = F.relu(self.conv2(x))\n","#         x = F.max_pool2d(x, kernel_size=2, stride=2)\n","#         # Flatten the output for fully connected layers\n","#         x = x.view(-1, 32 * 8 * 8)\n","#         # Fully connected layers with ReLU activation\n","#         x = F.relu(self.fc1(x))\n","#         # Output layer with sigmoid activation for binary classification\n","#         x = torch.sigmoid(self.fc2(x))\n","#         # x = x > 0.5\n","#         return x\n","\n","# tinymodel = TinyModel()\n","# BATCH_SIZE = 32\n","# LEARNING_RATE = 1e-3\n","\n","# print('The model: ', tinymodel)\n","\n","# # Define the loss function\n","# loss_fn = torch.nn.BCELoss()\n","\n","# # Define the optimizer\n","# optimizer = torch.optim.SGD(tinymodel.parameters(), lr=LEARNING_RATE)\n","\n","# # Load the data\n","# train_dataloader = torch.utils.data.DataLoader(training_data, BATCH_SIZE, shuffle=True)\n","\n","# # Train the model\n","# def train(dataloader, model, loss_fn, optimizer):\n","#     size = len(dataloader.dataset)\n","#     for batch, (X, y) in enumerate(dataloader):\n","#         # Compute prediction and loss\n","#         pred = model(X.float())\n","#         print(pred)\n","#         print('Interval: ', pred.min(), pred.max())\n","#         y = y.reshape(-1, 1).float()\n","#         loss = loss_fn(pred, y)\n","#         # Backpropagation\n","#         optimizer.zero_grad()\n","#         loss.backward()\n","#         optimizer.step()\n","#         if batch % 10 == 0:\n","#             loss, current = loss.item(), batch * len(X)\n","#             print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n","\n","# epochs = 5\n","# for t in range(epochs):\n","#     print(f\"Epoch {t+1}\\n-------------------------------\")\n","#     train(train_dataloader, tinymodel, loss_fn, optimizer)"]},{"cell_type":"markdown","metadata":{},"source":["TODO: Try to preprocess like in ImProc"]},{"cell_type":"code","execution_count":54,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([3, 224, 224])\n"]}],"source":["from torchvision.models import resnet18\n","from torchvision.transforms import Normalize\n","import torchvision.transforms as transforms\n","\n","mean = [0.485, 0.456, 0.406]\n","std = [0.229, 0.224, 0.225]\n","\n","transform = transforms.Compose([\n","    transforms.Resize(256),\n","    transforms.CenterCrop(224),\n","    transforms.ConvertImageDtype(torch.float32),\n","    transforms.Normalize(mean=mean, std=std),\n","])\n","training_dataset = CactusDataset(annotations_file, img_dir, transform=transform)\n","\n","print(training_dataset[0][0].shape)"]},{"cell_type":"code","execution_count":56,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Training set size: 3200\n","Validation set size: 14300\n"]}],"source":["from torch.utils.data import random_split\n","\n","# Define the sizes of training and validation sets\n","train_size = 3200 # int(0.8 * len(training_dataset))\n","val_size = len(training_dataset) - train_size\n","\n","# Split the dataset into training and validation sets\n","train_data, val_data = random_split(training_dataset, [train_size, val_size])\n","\n","# Print the sizes of the training and validation sets\n","print(\"Training set size:\", len(train_data))\n","print(\"Validation set size:\", len(val_data))"]},{"cell_type":"code","execution_count":57,"metadata":{},"outputs":[],"source":["import torch.nn as nn\n","\n","class ResnetClassificator(nn.Module):\n","    def __init__(self):\n","        super(ResnetClassificator, self).__init__()\n","        self.resnet = resnet18(pretrained=True)\n","        last_layer_size = self.resnet.fc.out_features # 1000        \n","        self.fc = nn.Linear(last_layer_size, 1)\n","\n","    def forward(self, x):\n","        x = self.resnet(x)\n","        x = self.fc(x)\n","        return x"]},{"cell_type":"code","execution_count":60,"metadata":{},"outputs":[],"source":["model = ResnetClassificator()\n","criterion = nn.BCEWithLogitsLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n","\n","# Train the model\n","train_dataloader = torch.utils.data.DataLoader(training_dataset, BATCH_SIZE, shuffle=True)\n","\n","\n","for batch, (X, y) in enumerate(train_dataloader):\n","    # Compute prediction and loss\n","    pred = model(X.float())\n","    # print(pred)\n","    # print('Interval: ', pred.min(), pred.max())\n","    y = y.reshape(-1, 1).float()\n","    loss = criterion(pred, y)\n","    # Backpropagation\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","    if batch % 10 == 0:\n","        loss, current = loss.item(), batch * len(X)\n","        print(f\"loss: {loss:>7f}  [{current:>5d}/{train_size:>5d}]\")"]},{"cell_type":"code","execution_count":50,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([-0.5271])\n","tensor([1.])\n","tensor(0)\n"]}],"source":["# input_tensor = training_dataset[0][0]\n","# input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n","\n","# model = ResnetClassificator()\n","# with torch.no_grad():\n","#     output = model(input_batch)\n","# # Tensor of shape 1000, with confidence scores over ImageNet's 1000 classes\n","# print(output[0])\n","# # The output has unnormalized scores. To get probabilities, you can run a softmax on it.\n","# probabilities = torch.nn.functional.softmax(output[0], dim=0)\n","# print(probabilities)\n","# print(torch.argmax(probabilities))"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":4736944,"sourceId":8035608,"sourceType":"datasetVersion"}],"isGpuEnabled":false,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
