fc_sizes = [6, 12, 24]
dropouts = [0.1, 0.3, 0.5]
%matplotlib inline

best_models = []

for fc_size in fc_sizes:
    for dropout in dropouts:
        
        print(f'>>>>>>>>     FC Size: {fc_size} - Dropout: {dropout}     <<<<<<<<')
        # Create the model
        model = CustomConvNet(fc_size=fc_size, dropout=dropout).to(device)

        # Define the loss function and optimizer
        criterion = nn.BCEWithLogitsLoss().to(device)
        optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)

        # Create the dataloaders
        train_dataloader = torch.utils.data.DataLoader(train_data, BATCH_SIZE, shuffle=True)
        val_dataloader = torch.utils.data.DataLoader(val_data, BATCH_SIZE, shuffle=False)

        train_losses = []
        val_losses = []
        err_rates = []
        f1_scores = []
        early_stopper = EarlyStopper(patience=10, min_delta=5e-4)
        best_epoch = None

        for epoch in range(EPOCHS):
            train_loss = train_model(train_dataloader, model, criterion, optimizer, checkpoint=False, desc=f'TrainingEpoch{(epoch + 1):02d}')
            val_loss, errors, confusion_matrix = evaluate(val_dataloader, model, criterion, desc=f'ValidationEpoch{(epoch + 1):02d}')
            train_losses.append(train_loss)
            val_losses.append(val_loss)
            error_rate = (sum(errors) / len(val_data)).item()
            err_rates.append(error_rate)
            f1 = f1_score(confusion_matrix)
            f1_scores.append(f1)
            fpr = confusion_matrix[0][1] / (confusion_matrix[0][0] + confusion_matrix[0][1])
            fnr = confusion_matrix[1][0] / (confusion_matrix[1][0] + confusion_matrix[1][1])
            print(f'Epoch {epoch + 1}/{EPOCHS}\t Train Loss: {train_loss:.4f} - Val Loss: {val_loss:.4f} - Error Rate: {error_rate:.4f} - F1 Score: {f1:.4f} - (FPR: {fpr:.4f} - FNR: {fnr:.4f})')
            if best_epoch is None or val_loss < val_losses[best_epoch]:
                best_epoch = epoch
                save_checkpoint(model, optimizer, val_loss, f'custom3/fc_{fc_size}_dropout_{dropout}_lr_{LEARNING_RATE}', f'epoch{epoch+1}')

            if early_stopper.early_stop(val_loss):
                print(f'Early stopping on epoch {epoch + 1}')
                break
        
        fig, ax = plt.subplots(2, 1, figsize=(10, 13))
        fig.suptitle(f'FC Size: {fc_size} - Dropout: {dropout}', fontsize=25, fontweight='bold')
        
        ax[0].set_title('Loss', fontsize=25)
        ax[1].set_title('Error Rate (validation)', fontsize=25)
        
        epochs = [i+1 for i in range(len(train_losses))]
        ax[0].plot(epochs, train_losses, label='Train Loss', color='tab:blue')
        ax[0].plot(epochs, val_losses, label='Val Loss', color='tab:orange')
        ax[1].plot(epochs, err_rates, label='Error Rate', color='tab:blue')
        ax2 = ax[1].twinx()
        ax2.plot(epochs, f1_scores, color='tab:orange', label='F1 Score')
        
        epochs = [i for i in range(0, len(train_losses)+1, 5)]
        ax[0].set_xlabel('Epoch', fontsize=16)
        ax[0].set_xticks(epochs)
        ax[0].set_ylabel('Loss', fontsize=16)
        ax[0].legend(loc = 'best', fontsize=16)
        ax[1].set_xlabel('Epoch', fontsize=16)
        ax[1].set_xticks(epochs)
        ax[1].set_ylabel('Error Rate', fontsize=16)
        ax[1].legend(loc = 'best' , fontsize=16)
        ax2.set_ylabel('F1 Score')
        ax2.tick_params(axis='y', labelcolor='tab:orange')
        # Add legend
        lines, labels = ax[1].get_legend_handles_labels()
        lines2, labels2 = ax2.get_legend_handles_labels()
        ax2.legend(lines + lines2, labels + labels2, loc='best', fontsize=16)

        plt.show()
        fig_dir = os.path.join(FIGURES_DIR, f'custom')
        if not os.path.exists(fig_dir):
            os.makedirs(fig_dir)
        fig_path = os.path.join(fig_dir, f'fc_{fc_size}_dropout_{dropout}_lr_{LEARNING_RATE}.png')
        
        fig.savefig(fig_path)

        best_models.append({
            'fc_size': fc_size,
            'dropout': dropout,
            'best_epoch': best_epoch,
            'train_loss': train_losses[best_epoch],
            'val_loss': val_losses[best_epoch],
            'error_rate': err_rates[best_epoch],
            'f1_score': f1_scores[best_epoch],
            'fig_path': fig_path,
        })
